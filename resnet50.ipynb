{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU detected\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import h5py\n",
    "\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        print(f\"GPU Detected: {gpu.device_type} - {gpu.name}\")\n",
    "else:\n",
    "    print(\"No GPU detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3574, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the HDF5 file\n",
    "hdf5_file = 'processed_images_all.hdf5'\n",
    "with h5py.File(hdf5_file, 'r') as file:\n",
    "    # Read the test labels dataset into a numpy array\n",
    "    test_labels = file['test_images_labels'][:]\n",
    "\n",
    "# Create a DataFrame from the labels\n",
    "test_labels = pd.DataFrame(test_labels, columns=['label'])\n",
    "\n",
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect images file content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets contained within the file:\n",
      "Dataset Info: test_images, (3574, 224, 224, 3), float64\n",
      "Dataset Info: test_images_labels, (3574,), int32\n",
      "Dataset Info: train_images, (28561, 224, 224, 3), float64\n",
      "Dataset Info: train_images_labels, (28561,), int32\n",
      "Dataset Info: valid_images, (3579, 224, 224, 3), float64\n",
      "Dataset Info: valid_images_labels, (3579,), int32\n"
     ]
    }
   ],
   "source": [
    "# Function to inspect the contents of an HDF5 file\n",
    "def inspect_hdf5_file(filepath):\n",
    "    # Open the HDF5 file\n",
    "    with h5py.File(filepath, 'r') as file:\n",
    "        print(\"Datasets contained within the file:\")\n",
    "        for dataset_name in file:\n",
    "            # Access the dataset\n",
    "            dataset = file[dataset_name]\n",
    "            # Print details about the dataset\n",
    "            print(f\"Dataset Info: {dataset_name}, {dataset.shape}, {dataset.dtype}\")\n",
    "\n",
    "# Call the function to inspect the HDF5 file\n",
    "inspect_hdf5_file(hdf5_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a generator function to load images from the HDF5 file\n",
    "def hdf5_image_generator(filepath, dataset_name, batch_size):\n",
    "    while True:  # Loop indefinitely\n",
    "        with h5py.File(filepath, 'r') as file:\n",
    "            images = file[dataset_name]\n",
    "            labels = file[dataset_name + '_labels']  # Adjust if your labels are stored differently\n",
    "            num_samples = images.shape[0]\n",
    "\n",
    "            for start in range(0, num_samples, batch_size):\n",
    "                end = min(start + batch_size, num_samples)\n",
    "                yield images[start:end], labels[start:end]\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create generators for training and validation\n",
    "train_generator = hdf5_image_generator(hdf5_file, 'train_images', batch_size)\n",
    "valid_generator = hdf5_image_generator(hdf5_file, 'valid_images', batch_size)\n",
    "test_generator = hdf5_image_generator(hdf5_file, 'test_images', batch_size)\n",
    "\n",
    "# Get the lengths of the datasets\n",
    "def get_dataset_lengths(filepath):\n",
    "    with h5py.File(filepath, 'r') as file:\n",
    "        lengths = {}\n",
    "        for dataset_name in file:\n",
    "            dataset = file[dataset_name]\n",
    "            lengths[dataset_name] = len(dataset)\n",
    "    return lengths\n",
    "\n",
    "dataset_lengths = get_dataset_lengths(hdf5_file)\n",
    "train_steps_per_epoch = dataset_lengths['train_images'] // batch_size\n",
    "valid_steps = dataset_lengths['valid_images'] // batch_size\n",
    "test_steps = dataset_lengths['test_images'] // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early stopping callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement EarlyStopping callback function\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',   # Monitor the validation loss\n",
    "    patience=10,          # Number of epochs with no improvement after which training will be stopped\n",
    "    verbose=1,            # Log when training stops\n",
    "    restore_best_weights=True  # Restores model weights from the epoch with the best value of the monitored metric\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet50 model, similar adjustments as VGG16\n",
    "resnet50_base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "\n",
    "x = Flatten()(resnet50_base_model.output)\n",
    "\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "output = Dense(10, activation='softmax')(x)\n",
    "\n",
    "resnet50_model = Model(inputs=resnet50_base_model.input, outputs=output)\n",
    "resnet50_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "resnet50_model_history = resnet50_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps_per_epoch,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=valid_steps,\n",
    "    #callbacks=[early_stopping]  # Include the early stopping callback\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_model.save('models/resnet50_model_all.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Julio\\Uc3m\\TFG\\venv\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 12 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the .h5 file\n",
    "#resnet50_model = load_model('models/resnet50_model_all.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform evaluation\n",
    "test_loss, test_acc = resnet50_model.evaluate(test_generator, steps=test_steps)\n",
    "print(\"ResNet50 Model Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the history\n",
    "# Assuming 'history' is the output from your model.fit()\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(resnet50_model_history.history['loss'], label='Train Loss')\n",
    "plt.plot(resnet50_model_history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('ResNet50 Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Plot training & validation mean squared error\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(resnet50_model_history.history['accuracy'], label='Train accuracy')\n",
    "plt.plot(resnet50_model_history.history['val_accuracy'], label='Validation accuracy')\n",
    "plt.title('ResNet50 Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = resnet50_model.predict(test_generator, steps=test_steps)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "test_labels, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "print(\"ResNet50 Model Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, predicted_labels)\n",
    "print(\"ResNet50 Model Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=emotion_labels.values(), yticklabels=emotion_labels.values(), cbar=False)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('ResNet50 Model Confusion Matrix')\n",
    "\n",
    "# Move the X-axis to the top of the plot\n",
    "ax.xaxis.tick_top()  # X-axis on top\n",
    "ax.xaxis.set_label_position('top')  # Move the x-axis label to the top\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
